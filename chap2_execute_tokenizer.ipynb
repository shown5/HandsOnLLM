{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOsXGH/t6oTYROmQtX0Dm6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shown5/HandsOnLLM/blob/main/chap2_execute_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers>=4.41.2 sentence-transformers>=3.0.1 gensim>=4.3.2 scikit-learn>=1.5.0 accelerate>=0.31.0"
      ],
      "metadata": {
        "id": "PDuTJl_md7_0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b18337a"
      },
      "source": [
        "%pip install -U numpy torch transformers accelerate bitsandbytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89LWgmA6ju17"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# „É¢„Éá„É´„Å®„Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº„ÇíË™≠„ÅøËæº„ÇÄ\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\", # Corrected model name\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=torch.float16, # Corrected torch_dtype\n",
        "    trust_remote_code=False,\n",
        "    # attn_implementation='eager' # Add this line\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\") # Corrected model name"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÊÇ≤ÊÉ®„Å™„Ç¨„Éº„Éá„Éã„É≥„Ç∞„Åß„ÅÆÁÅΩÈõ£„Å´„Å§„ÅÑ„Å¶„ÄÅ„Åï„Çâ„Å´Ë¨ùÁΩ™„ÅÆ„É°„Éº„É´„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "# „Å©„ÅÜ„Åó„Å¶„Åù„Çì„Å™„Åì„Å®„ÅåËµ∑„Åç„Åü„ÅÆ„ÅãË™¨Êòé„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
        "prompt = \"Write an emaik appologizing to Sarah for the tragic gardening mishap. Explain how it happend.<|assinstant|>\"\n",
        "\n",
        "# ÂÖ•Âäõ„Éó„É≠„É≥„Éó„Éà„Çí„Éà„Éº„ÇØ„É≥Âåñ„Åô„Çã\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
        "\n",
        "# „ÉÜ„Ç≠„Çπ„Éà„ÅÆÁîüÊàê\n",
        "generation_output = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_new_tokens=20\n",
        ")\n",
        "\n",
        "# Âá∫Âäõ„ÅÆË°®Á§∫\n",
        "print(tokenizer.decode(generation_output[0]))"
      ],
      "metadata": {
        "id": "bCd5MtGukgoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_ids)"
      ],
      "metadata": {
        "id": "RUMK82fmtIsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for id in input_ids[0]:\n",
        "  print(tokenizer.decode(id))"
      ],
      "metadata": {
        "id": "At_DoVMNtO6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_output"
      ],
      "metadata": {
        "id": "HofMM2kCe9bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(2250))\n",
        "print(tokenizer.decode(355))\n",
        "print(tokenizer.decode(19423))"
      ],
      "metadata": {
        "id": "WZAUof9sfBbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "colors_list = [\n",
        "    '102;194;165', '252;141;98', '141;160;203',\n",
        "    '231;138;195', '166;216;84', '255;217;47'\n",
        "]\n",
        "\n",
        "def show_tokens(sentence, tokenizer_name):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "  token_ids = tokenizer(sentence).input_ids\n",
        "  for idx, t in enumerate(token_ids):\n",
        "    print(\n",
        "        f'\\x1b[0;30;48;2;{colors_list[idx % len(colors_list)]}m' +\n",
        "        tokenizer.decode(t) +\n",
        "        '\\x1b[0m',\n",
        "        end=' '\n",
        "    )"
      ],
      "metadata": {
        "id": "VfxHjQAUrfEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "English and CAPITALIZATION\n",
        "üéµ È∏ü\n",
        "show_tokens False None elif == >= else: two tabs:\"    \" Three tabs:\"      \"\n",
        "12.0*50=600\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lUOpWrfOqXnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"bert-bose-uncased\")"
      ],
      "metadata": {
        "id": "S3ERegCXrTb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"bert-base-cased\")"
      ],
      "metadata": {
        "id": "BOhsWOzFuT0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"gpt2\")"
      ],
      "metadata": {
        "id": "Y_GeFi0mudlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"google/flan-t5-small\")"
      ],
      "metadata": {
        "id": "TY8P8K1UutBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"Xenova/gpt-4\")"
      ],
      "metadata": {
        "id": "hiSVGu8Xu0uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"bigcode/starcoder2-15b\")"
      ],
      "metadata": {
        "id": "J0OcfUBuu6IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"facebook/galactica-1.3b\")"
      ],
      "metadata": {
        "id": "FZaEDtW_vJka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text, \"microsoft/Phi-3-mini-4k-instruct\")"
      ],
      "metadata": {
        "id": "3jCm5xiuvJje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}